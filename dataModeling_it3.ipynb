{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artists_num', 'album_num_tracks', 'peak_rank', 'weeks_on_chart',\n",
      "       'streams', 'danceability', 'energy', 'key', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'duration', 'release_year', 'release_month', 'release_day',\n",
      "       'release_dayofweek', 'loudness_log', 'energy_danceability_interaction'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists_num</th>\n",
       "      <th>album_num_tracks</th>\n",
       "      <th>peak_rank</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>streams</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_dayofweek</th>\n",
       "      <th>loudness_log</th>\n",
       "      <th>energy_danceability_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>36.50000</td>\n",
       "      <td>37158272</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.620</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.30900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.962</td>\n",
       "      <td>117.399</td>\n",
       "      <td>164459</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.399162</td>\n",
       "      <td>0.466240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>215055522</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.627</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.13100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.524</td>\n",
       "      <td>120.963</td>\n",
       "      <td>188491</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3.382558</td>\n",
       "      <td>0.468996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>48580</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.683</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.73700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.493</td>\n",
       "      <td>128.018</td>\n",
       "      <td>157987</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.454675</td>\n",
       "      <td>0.399555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>9944865</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.755</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.08220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.437</td>\n",
       "      <td>191.153</td>\n",
       "      <td>193680</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3.374134</td>\n",
       "      <td>0.266515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>129.30303</td>\n",
       "      <td>429376201</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.236</td>\n",
       "      <td>148.033</td>\n",
       "      <td>222973</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.409331</td>\n",
       "      <td>0.320672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25835</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>6885448</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.634</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.05640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.463</td>\n",
       "      <td>124.074</td>\n",
       "      <td>174194</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3.418218</td>\n",
       "      <td>0.514808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25836</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>421278</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.469</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.33300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.353</td>\n",
       "      <td>114.017</td>\n",
       "      <td>144737</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.325360</td>\n",
       "      <td>0.371448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25837</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>8.50000</td>\n",
       "      <td>11300755</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.504</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.401</td>\n",
       "      <td>165.860</td>\n",
       "      <td>155714</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.237580</td>\n",
       "      <td>0.209160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25838</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>171</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>13137028</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.10100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.340</td>\n",
       "      <td>154.962</td>\n",
       "      <td>179773</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>3.380042</td>\n",
       "      <td>0.531960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>12089312</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.864</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.08580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.833</td>\n",
       "      <td>169.123</td>\n",
       "      <td>167503</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3.453948</td>\n",
       "      <td>0.514944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25840 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       artists_num  album_num_tracks  peak_rank  weeks_on_chart    streams  \\\n",
       "0                1                15          4        36.50000   37158272   \n",
       "1                2                 1         46         9.00000  215055522   \n",
       "2                1                13         61         2.00000      48580   \n",
       "3                1                 1        112         1.50000    9944865   \n",
       "4                1                12         44       129.30303  429376201   \n",
       "...            ...               ...        ...             ...        ...   \n",
       "25835            1                 1          4        27.00000    6885448   \n",
       "25836            3                 1          7        10.00000     421278   \n",
       "25837            1                 7         40         8.50000   11300755   \n",
       "25838            2                11        171         1.50000   13137028   \n",
       "25839            1                 9         60         6.00000   12089312   \n",
       "\n",
       "       danceability  energy  key  speechiness  acousticness  ...  liveness  \\\n",
       "0             0.752   0.620    5       0.0509       0.30900  ...    0.0750   \n",
       "1             0.748   0.627    7       0.0639       0.13100  ...    0.0852   \n",
       "2             0.585   0.683    8       0.0523       0.73700  ...    0.1140   \n",
       "3             0.353   0.755    1       0.7330       0.08220  ...    0.3900   \n",
       "4             0.352   0.911    1       0.0747       0.00121  ...    0.0995   \n",
       "...             ...     ...  ...          ...           ...  ...       ...   \n",
       "25835         0.812   0.634    8       0.1630       0.05640  ...    0.2760   \n",
       "25836         0.792   0.469    8       0.1070       0.33300  ...    0.0725   \n",
       "25837         0.415   0.504    9       0.0318       0.02200  ...    0.3630   \n",
       "25838         0.744   0.715    0       0.3510       0.10100  ...    0.0919   \n",
       "25839         0.596   0.864    8       0.0400       0.08580  ...    0.1580   \n",
       "\n",
       "       valence    tempo  duration  release_year  release_month  release_day  \\\n",
       "0        0.962  117.399    164459          2021              4           22   \n",
       "1        0.524  120.963    188491          2017              3           23   \n",
       "2        0.493  128.018    157987          2022              2           14   \n",
       "3        0.437  191.153    193680          2018              6           15   \n",
       "4        0.236  148.033    222973          2004              1            1   \n",
       "...        ...      ...       ...           ...            ...          ...   \n",
       "25835    0.463  124.074    174194          2020             12           18   \n",
       "25836    0.353  114.017    144737          2022              2            4   \n",
       "25837    0.401  165.860    155714          2018             10            5   \n",
       "25838    0.340  154.962    179773          2017              2           24   \n",
       "25839    0.833  169.123    167503          2021              6           24   \n",
       "\n",
       "       release_dayofweek  loudness_log  energy_danceability_interaction  \n",
       "0                      3      3.399162                         0.466240  \n",
       "1                      3      3.382558                         0.468996  \n",
       "2                      0      3.454675                         0.399555  \n",
       "3                      4      3.374134                         0.266515  \n",
       "4                      3      3.409331                         0.320672  \n",
       "...                  ...           ...                              ...  \n",
       "25835                  4      3.418218                         0.514808  \n",
       "25836                  4      3.325360                         0.371448  \n",
       "25837                  4      3.237580                         0.209160  \n",
       "25838                  4      3.380042                         0.531960  \n",
       "25839                  3      3.453948                         0.514944  \n",
       "\n",
       "[25840 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing relevant libraries for the further programming. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Read Dataset\n",
    "cleaned_df = pd.read_excel('SpotifyDataIt3.xlsx')\n",
    "\n",
    "# Print column names to inspect\n",
    "print(cleaned_df.columns)\n",
    "\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we initiate the training of DecisionTreeRegressor (DT) and split the data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3157696158114045.0\n",
      "Root Mean Squared Error: 56193381.79994193\n",
      "R-squared: 0.2433036819444082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Selecting relevant columns for the model\n",
    "# 'streams' is the target variable and excluding highly categorical columns for simplicity\n",
    "relevant_columns = ['artists_num', 'album_num_tracks', 'peak_rank', 'weeks_on_chart','streams', 'danceability', 'energy', 'key', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','duration', 'release_year', 'release_month', 'release_day',\n",
    "'release_dayofweek', 'loudness_log', 'energy_danceability_interaction',]\n",
    "data_for_model = cleaned_df[relevant_columns]\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X = data_for_model.drop('streams', axis=1)\n",
    "y = data_for_model['streams']\n",
    "\n",
    "# Test size is 30% and training are 70%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the Decision Tree Regressor and adjusting model complexity\n",
    "# Models complexity have been selected based on several tries, and what performed the \"best\".\n",
    "dt_regressor = DecisionTreeRegressor(max_depth=5, min_samples_split=20, min_samples_leaf=15, random_state=0)\n",
    "\n",
    "#Fitting the model\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = dt_regressor.predict(X_test)\n",
    "\n",
    "#Calculating MSE, RMSE and R-squared \n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the model within a practical time frame, we can try a few adjustments:\n",
    "\n",
    "Let's start with a reduced and more focused hyperparameter space for the Decision Tree Regressor\n",
    "\n",
    "this method is also calling pre-pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3157891529306692.0\n",
      "Root Mean Squared Error: 56195120.15563889\n",
      "Test R-squared: 0.2433036819444082\n"
     ]
    }
   ],
   "source": [
    "#Importing gridseachCV for further optimization of the model. \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize a Random Forest Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_dt = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fitting the GridSearchCV\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best estimators Decision Tree \n",
    "best_dt_model = grid_search_dt.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test data\n",
    "y_pred_test = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE, RMSE R-squared \n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Test R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the tuning - reducing the set of parameters for tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "best_MSE_reduced: 3139394975750538.0\n",
      "best_RMSE_reduced: 56030304.084044896\n",
      "R-Squared: 0.2432568640573387\n"
     ]
    }
   ],
   "source": [
    "# Define a reduced set of parameters for tuning\n",
    "param_grid_reduced = {\n",
    "    'max_depth': [1, 3, 6],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with reduced parameter grid that are declared above\n",
    "grid_search_reduced = GridSearchCV(estimator=dt_regressor, param_grid=param_grid_reduced, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search_reduced.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best MSE \n",
    "best_params = grid_search_reduced.best_params_\n",
    "best_mse = -grid_search_reduced.best_score_\n",
    "\n",
    "\n",
    "# Best parameters, MSE and r-squared on the test data \n",
    "best_params_reduced = grid_search_reduced.best_params_\n",
    "best_mse_reduced = -grid_search_reduced.best_score_\n",
    "best_rmse_reduced = np.sqrt(best_mse_reduced)\n",
    "best_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print('best params:', best_params_reduced)\n",
    "print('best_MSE_reduced:', best_mse_reduced)\n",
    "print('best_RMSE_reduced:', best_rmse_reduced)\n",
    "print('R-Squared:', best_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at Random Forrest Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanna do the same approach as above but for the random forrest regression model. We are training the model on the training set, and evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2845150055654778.5\n",
      "Root Mean Squared Error: 53339948.0282347\n",
      "R-squared: 0.31820084529112025\n"
     ]
    }
   ],
   "source": [
    "# import relevant libraries to training Random Forest Regressor. \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# X and y have been defined in the code above. \n",
    "\n",
    "# Initializing and training the Random Forrest Regressor and adjusting model complexity\n",
    "# Models complexity have been selected based on several tries, and what performed the \"best\".\n",
    "rf_regressor = RandomForestRegressor(max_depth=15, min_samples_split=75, min_samples_leaf=25, random_state=0)\n",
    "\n",
    "# Fitting the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the model within a practical time frame we are trying with the following:\n",
    " \n",
    "reduced and more focused hyperparameter space for the Random Forest Regressor\n",
    "\n",
    "this method is also calling pre-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Model Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Root Mean Squared Error: 52157749.4295785\n",
      "test MSE: 2720430825558696.0\n",
      "test R-squared: 0.34808800905826354\n"
     ]
    }
   ],
   "source": [
    "#Libraries and other code have been declared the code snippets above.\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_rf = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best Random Forest model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Make predictions using the best model on the test data\n",
    "y_pred_test = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R-squared for the test data\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Best Random Forest Model Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"test MSE:\", test_mse)\n",
    "print(\"test R-squared:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the tuning - reducing the set of parameters for tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Root Mean Squared Error: 52154295.856008254\n",
      "test MSE: 2720070576236040.0\n",
      "Test R-squared: 0.34817433760996275\n"
     ]
    }
   ],
   "source": [
    "#Libraries and other relevant code have been declared the snippets above.\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object with the same parameter grid and model\n",
    "grid_search_reduced = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search_reduced.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model and its parameters\n",
    "best_rf_model_reduced = grid_search_reduced.best_estimator_\n",
    "best_params_reduced = grid_search_reduced.best_params_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test_reduced = best_rf_model_reduced.predict(X_test)\n",
    "\n",
    "# Calculate R-squared for the test data\n",
    "test_r2_reduced = r2_score(y_test, y_pred_test_reduced)\n",
    "test_mse_reduced = mean_squared_error(y_test, y_pred_test_reduced)\n",
    "rmse = np.sqrt(test_mse_reduced)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Best Parameters:\", best_params_reduced)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"test MSE:\", test_mse_reduced)\n",
    "print(\"Test R-squared:\", test_r2_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how linear regression perform:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 60418432.648560435\n",
      "test MSE: 3650387003708633.5\n",
      "Test R-squared: 0.08279784727712935\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries and loading the dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Root Mean Squared Error:\", rmse_linear)\n",
    "print(\"test MSE:\", mse_linear )\n",
    "print(\"Test R-squared:\", r2_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of we cross validate the linear regression model to evalute the models performance, because GridSearchCV is not a possibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61466224.18909626, 62199008.53080785, 59645209.04620065,\n",
       "       62158663.4592537 , 62029685.81215119])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert MSE scores to RMSE scores\n",
    "rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Output the cross-validation RMSE scores\n",
    "rmse_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred = cross_val_predict(linear_model, X, y, cv=5)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Plotting the residuals\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look how the Lasso perform compared to linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Lasso): 3823608305186181.0, RMSE (Lasso): 61835332.17494818, R-squared (Lasso): 0.0837274451544402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Start by finding the best alpha for the L1 regression to optimize the model\n",
    "# Setting up a range of alpha values to test\n",
    "alphas = np.logspace(-4, 0.01, 10)\n",
    "\n",
    "# Initialize and train the LassoCV model to find the best alpha\n",
    "lasso_cv_model = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# Optimal alpha found by LassoCV\n",
    "optimal_alpha = lasso_cv_model.alpha_\n",
    "\n",
    "# Initialize the Lasso regression model (L1 regularization)\n",
    "# Setting the alpha to the optimal alpha found above\n",
    "lasso_model = Lasso(alpha=optimal_alpha, random_state=30)\n",
    "\n",
    "# Training the Lasso regression model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(f'MSE (Lasso): {mse_lasso}, RMSE (Lasso): {rmse_lasso}, R-squared (Lasso): {r2_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try further explore the model and make it better we implement a GridSearch for the Lasso regression model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100, 'max_iter': 1000, 'tol': 0.0001}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Define the parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100],\n",
    "    'max_iter': [1000, 5000, 10000],\n",
    "    'tol': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=Lasso(random_state=42), param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "# Output the best parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the \"best parameters\" to see the change in MSE, RMSE and R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Lasso): 3650393662497365.0, RMSE (Lasso): 60418487.75414165, R-squared (Lasso): 0.08279617417908447\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lasso regression model with the best parameters\n",
    "best_lasso_model = Lasso(**best_parameters, random_state=42)\n",
    "\n",
    "# Training the Lasso regression model with the best parameters\n",
    "best_lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results using the best model\n",
    "y_pred_best_lasso = best_lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluating the best model\n",
    "mse_best_lasso = mean_squared_error(y_test, y_pred_best_lasso)\n",
    "rmse_best_lasso = np.sqrt(mse_best_lasso)\n",
    "r2_best_lasso = r2_score(y_test, y_pred_best_lasso)\n",
    "\n",
    "print(f'MSE (Lasso): {mse_best_lasso}, RMSE (Lasso): {rmse_best_lasso}, R-squared (Lasso): {r2_best_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to experiment with Gradiant Booster Regressor to see how it perform in iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (gbr): 2871076330363802.5, RMSE (gbr): 53582425.57372522, R-squared (gbr): 0.27860870966119944\n"
     ]
    }
   ],
   "source": [
    "#Here we create a gradient tree boosting regressor model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Initialize and train the Gradient Boosting Regressor and adjusting model complexity\n",
    "# Models complexity have been selected based on several tries, and what performed the \"best\".\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred_gbr = gbr_model.predict(X_test)\n",
    "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
    "rmse_gbr = np.sqrt(mse_gbr)\n",
    "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(f'MSE (gbr): {mse_gbr}, RMSE (gbr): {rmse_gbr}, R-squared (gbr): {r2_gbr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement Random Search for Gradient Booster Regressor, because GridSearch was to complex for Gradient Booster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "MSE (Best GBR): 2590181037793240.0, RMSE (Best GBR): 50893821.21430106, R-squared (Best GBR): 0.3491869159647206\n",
      "Best Parameters: {'learning_rate': 0.13022300234864176, 'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 102, 'subsample': 0.9939819704323989}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "\n",
    "# X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Define the parameter distributions for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(2, 6),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'subsample': uniform(0.8, 0.2)\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV object for GradientBoostingRegressor\n",
    "random_search_gbr = RandomizedSearchCV(estimator=GradientBoostingRegressor(random_state=42), \n",
    "                                       param_distributions=param_distributions, \n",
    "                                       n_iter=10, \n",
    "                                       scoring='neg_mean_squared_error', \n",
    "                                       cv=5, \n",
    "                                       random_state=42,\n",
    "                                       verbose=1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_parameters_gbr = random_search_gbr.best_params_\n",
    "\n",
    "# Using the best parameters to train and evaluate the model\n",
    "best_gbr_model = GradientBoostingRegressor(**best_parameters_gbr, random_state=42)\n",
    "best_gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the best model\n",
    "y_pred_best_gbr = best_gbr_model.predict(X_test)\n",
    "mse_best_gbr = mean_squared_error(y_test, y_pred_best_gbr)\n",
    "rmse_best_gbr = np.sqrt(mse_best_gbr)\n",
    "r2_best_gbr = r2_score(y_test, y_pred_best_gbr)\n",
    "\n",
    "# Print the evaluation metrics for the best model\n",
    "print(f'MSE (Best GBR): {mse_best_gbr}, RMSE (Best GBR): {rmse_best_gbr}, R-squared (Best GBR): {r2_best_gbr}')\n",
    "print(f'Best Parameters: {best_parameters_gbr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wanna try to do the same, but using XGBoost Regressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2974540718945119.0\n",
      "Root Mean Squared Error: 54539350.188145064\n",
      "R-squared: 0.28719423996876126\n"
     ]
    }
   ],
   "source": [
    "#Implementing a XGBoost model\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize and train the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "# Returning the evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse_xgb)\n",
    "print(\"Root Mean Squared Error:\", rmse_xgb)\n",
    "print(\"R-squared:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use gridsearch to further investigate and tune the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreasmaskine/Desktop/CM(it)/Big Data/Big Data Eksamen/BigDataSpotify/dataModeling_it3.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grid_search_xgb \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mXGBRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                param_grid\u001b[39m=\u001b[39mparam_grid, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Fit GridSearchCV\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m grid_search_xgb\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Best parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreasmaskine/Desktop/CM%28it%29/Big%20Data/Big%20Data%20Eksamen/BigDataSpotify/dataModeling_it3.ipynb#X43sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m best_parameters_xgb \u001b[39m=\u001b[39m grid_search_xgb\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m (\n\u001b[1;32m   1078\u001b[0m     model,\n\u001b[1;32m   1079\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1085\u001b[0m )\n\u001b[0;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1087\u001b[0m     params,\n\u001b[1;32m   1088\u001b[0m     train_dmatrix,\n\u001b[1;32m   1089\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39mevals,\n\u001b[1;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39mevals_result,\n\u001b[1;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39mobj,\n\u001b[1;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39mmetric,\n\u001b[1;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1098\u001b[0m )\n\u001b[1;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m-> 2050\u001b[0m         _LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[1;32m   2051\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, ctypes\u001b[39m.\u001b[39mc_int(iteration), dtrain\u001b[39m.\u001b[39mhandle\n\u001b[1;32m   2052\u001b[0m         )\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a range of hyperparameters for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object for XGBRegressor\n",
    "grid_search_xgb = GridSearchCV(estimator=XGBRegressor(random_state=42), \n",
    "                               param_grid=param_grid, \n",
    "                               scoring='neg_mean_squared_error', \n",
    "                               cv=5, \n",
    "                               verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_parameters_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "# Output the best parameters\n",
    "best_parameters_xgb\n",
    "\n",
    "# Using the best parameters to train and evaluate the model\n",
    "best_xgb_model = XGBRegressor(**best_parameters_xgb, random_state=42)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the best model\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "mse_best_xgb = mean_squared_error(y_test, y_pred_best_xgb)\n",
    "rmse_best_xgb = np.sqrt(mse_best_xgb)\n",
    "r2_best_xgb = r2_score(y_test, y_pred_best_xgb)\n",
    "\n",
    "# Print the evaluation metrics for the best model\n",
    "print('Best Mean Square Error:', mse_best_xgb) \n",
    "print('Best Root Mean Square Error:', rmse_best_xgb) \n",
    "print('Best R-squared:', r2_best_xgb)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
