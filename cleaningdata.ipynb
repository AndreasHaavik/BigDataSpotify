{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we want to group our dataset with the 'uri' using the groupby function, which presumably contains unique identifiers for each track.\n",
    "\n",
    "For each group (unique 'uri'), various aggregate functions are applied: artist_names, artist_num, artist_genre and collab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#First of, we want to create a new attribute that shows the week number, based on the date as we will use this later\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('/Users/andreasmaskine/Desktop/CM(it)/Big Data/Big data rod/Book4.xlsx')\n",
    "\n",
    "#We combine our dataset with the 'uri' using the groupby function, to avoid duplicates, and for easier handling the data for further work. \n",
    "\n",
    "combined_df = df.groupby('uri').agg({\n",
    "    'artist_names':'first',\n",
    "    'artists_num':'first',\n",
    "    'artist_genre':', '.join,\n",
    "    'collab':'first', \n",
    "    'track_name':'first',\n",
    "    'release_date':'first',\n",
    "    'album_num_tracks':'first',\n",
    "    'source':'first',\n",
    "    'peak_rank':'first',\n",
    "    'weeks_on_chart': 'mean',\n",
    "    'streams': 'sum', \n",
    "    'danceability':'first',\n",
    "    'energy':'first',\n",
    "    'key':'first',\n",
    "    'loudness':'first',\n",
    "    'speechiness':'first',\n",
    "    'acousticness':'first',\n",
    "    'instrumentalness':'first',\n",
    "    'liveness':'first',\n",
    "    'valence':'first',\n",
    "    'tempo':'first',\n",
    "    'duration':'first',\n",
    "    }).reset_index()\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no duplicate found\n"
     ]
    }
   ],
   "source": [
    "#checking if the code run well, by looking for duplicates, which was trying to get remove from the code above. \n",
    "\n",
    "duplicate_rows = combined_df[combined_df.duplicated(subset=['uri'], keep=False )]\n",
    "\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Rows with duplicate 'uri':\")\n",
    "    print(duplicate_rows)\n",
    "else:  \n",
    "    print('no duplicate found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merch the data into an excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new data file and store the data in SpotifyDataAgg.xlsx\n",
    "combined_df.to_excel('SpotifyDataAgg.xlsx', index=False)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if there are missing values in the dataset and if there is, how do we then handle it? \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "combined_df = pd.read_excel('SpotifyDataAgg.xlsx')\n",
    "for col in combined_df:\n",
    "    print (combined_df[col].isnull().sum(), 'missing values in', col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Checking which rows are missing values and after declare if it is MCAR or MNAR - random or on purpose that there is missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the rows that are missing values. \n",
    "missing_values=combined_df[combined_df[col].isnull()]\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes missing values \n",
    "cleaned_df=combined_df.dropna(subset=[col])\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merching the new data into a new excel file. \n",
    "cleaned_df.to_excel('SpotifyDataClean.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was found relevant to clean out uri because the attribute is irrelevant now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unique attributes URI and track names:\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('SpotifyDataClean.xlsx')\n",
    "\n",
    "# List of attributes to remove\n",
    "attributes_to_remove = ['uri', 'track_name']\n",
    "\n",
    "# Remove specified attributes\n",
    "df = df.drop(attributes_to_remove, axis=1)\n",
    "\n",
    "# Save the modified DataFrame to a new Excel file\n",
    "df.to_excel('SpotifyDataCleaned.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the code runned successfully. \n",
    "cleaned_df=pd.read_excel('SpotifyDataCleaned.xlsx')\n",
    "print(cleaned_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e8995cc79525bd2f03bf06fe7351d86fcc477a350b98b661267de2f13aa6250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
